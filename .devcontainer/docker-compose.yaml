# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
---
services:
  airflow:
    stdin_open: true # docker run -i
    tty: true # docker run -t
    image: ghcr.io/apache/airflow/main/ci/python3.12
    env_file: .env
    ports:
      - "8080:8080"
      - "5555:5555"
      - "6379:6379"
    cap_add:
      - SYS_PTRACE
    volumes:
      # Pass docker to inside of the container so that Kind and Moto tests can use it.
      - /var/run/docker.sock:/var/run/docker.sock
      - /dev/urandom:/dev/random # Required to get non-blocking entropy source
      # Mount the cloned repo from codspaces docker host into the container,
    working_dir: /opt/airflow
    command: >
      bash -c "
        echo 'Container started, use make start to launch Airflow' &&
        sleep infinity
      "
    environment:
      - BACKEND=postgres
      - AIRFLOW__CORE__DAGS_FOLDER=/opt/airflow/dags
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:postgres@postgres/airflow
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://postgres:postgres@postgres/airflow
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=false
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=true
      - AIRFLOW__CORE__ENABLE_XCOM_PICKLING=true
      #JUST FOR TESTING, DO NOT USE IN PRODUCTION
      # The fernet key is used to encrypt sensitive data in Airflow.
      # It is recommended to generate a new key for production use.
      #AIRFLOW__CORE__FERNET_KEY=$(openssl rand -base64 32)
      - AIRFLOW__CORE__FERNET_KEY=5bSx0d3mFiOOzOIYxQyN8ybS2m+k10m6lce1ltH97dw=
    depends_on:
      postgres:
        condition: service_healthy

  postgres:
    image: postgres:10
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=airflow
      - POSTGRES_HOST_AUTH_METHOD=password
    ports:
      - "5432:5432"
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    healthcheck:
      test:
        [
          "CMD",
          "psql",
          "-h",
          "localhost",
          "-U",
          "postgres",
          "-c",
          "select 1",
          "airflow",
        ]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: "on-failure"
volumes:
  postgres-db-volume:
